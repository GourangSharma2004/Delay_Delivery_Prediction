{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics: {'accuracy': 0.452991452991453, 'precision': 0.75, 'recall': 0.23684210526315788, 'f1': 0.36, 'roc_auc': 0.56008303915276}\n",
      "Saved model to models/model.pkl and dataset to data/final_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# EDA, Preprocessing, Feature Engineering, Training, Export\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "\n",
    "# Resolve data directory robustly whether running from project root or notebooks/\n",
    "ROOT = os.getcwd()\n",
    "CANDIDATES = [\n",
    "    os.path.join(ROOT, 'data'),\n",
    "    os.path.abspath(os.path.join(ROOT, '..', 'data')),\n",
    "    os.path.abspath(os.path.join(ROOT, '..'))  # project root (in case files are directly there)\n",
    "]\n",
    "DATA_DIR = None\n",
    "for cand in CANDIDATES:\n",
    "    if os.path.exists(os.path.join(cand, 'orders.csv')):\n",
    "        DATA_DIR = cand\n",
    "        break\n",
    "# final fallback to parent data folder by name\n",
    "if DATA_DIR is None and os.path.exists(os.path.join(CANDIDATES[1])):\n",
    "    DATA_DIR = CANDIDATES[1]\n",
    "if DATA_DIR is None:\n",
    "    raise FileNotFoundError(f\"Could not locate CSVs. Tried: {CANDIDATES}\")\n",
    "\n",
    "# Load\n",
    "orders = pd.read_csv(os.path.join(DATA_DIR, 'orders.csv'))\n",
    "perf = pd.read_csv(os.path.join(DATA_DIR, 'delivery_performance.csv'))\n",
    "routes = pd.read_csv(os.path.join(DATA_DIR, 'routes_distance.csv'))\n",
    "fleet = pd.read_csv(os.path.join(DATA_DIR, 'vehicle_fleet.csv'))\n",
    "warehouse = pd.read_csv(os.path.join(DATA_DIR, 'warehouse_inventory.csv'))\n",
    "feedback = pd.read_csv(os.path.join(DATA_DIR, 'customer_feedback.csv'))\n",
    "costs = pd.read_csv(os.path.join(DATA_DIR, 'cost_breakdown.csv'))\n",
    "\n",
    "# Dates\n",
    "for df, cols in [\n",
    "    (orders, ['order_date']),\n",
    "    (perf, ['promised_delivery_time', 'actual_delivery_time'])\n",
    "]:\n",
    "    for c in cols:\n",
    "        if c in df.columns:\n",
    "            df[c] = pd.to_datetime(df[c], errors='coerce')\n",
    "\n",
    "# Merge on order_id where applicable\n",
    "for df in (orders, perf, routes, costs, feedback):\n",
    "    if 'order_id' in df.columns:\n",
    "        df['order_id'] = df['order_id'].astype(str)\n",
    "orders['origin_warehouse'] = orders['origin_warehouse'].astype(str)\n",
    "warehouse['warehouse_id'] = warehouse['warehouse_id'].astype(str)\n",
    "\n",
    "base = orders.merge(perf, on='order_id', how='left') \\\n",
    "             .merge(routes, on='order_id', how='left') \\\n",
    "             .merge(costs, on='order_id', how='left') \\\n",
    "             .merge(feedback[['order_id','rating']], on='order_id', how='left')\n",
    "base = base.merge(warehouse, left_on='origin_warehouse', right_on='warehouse_id', how='left')\n",
    "\n",
    "# Feature targets\n",
    "base['delivery_delay_minutes'] = (base['actual_delivery_time'] - base['promised_delivery_time']).dt.total_seconds() / 60\n",
    "base['delivery_delay_minutes'] = base['delivery_delay_minutes'].fillna(0)\n",
    "base['is_delayed'] = (base['delivery_delay_minutes'] > 0).astype(int)\n",
    "\n",
    "# Derived features\n",
    "base['promised_margin_min'] = (base['promised_delivery_time'] - base['order_date']).dt.total_seconds() / 60\n",
    "base['promised_margin_min'] = base['promised_margin_min'].fillna(base['promised_margin_min'].median())\n",
    "\n",
    "# Priority score\n",
    "priority_map = {'Express':3, 'Standard':2, 'Economy':1}\n",
    "if 'priority' in base.columns:\n",
    "    base['priority_score'] = base['priority'].map(priority_map).fillna(1)\n",
    "else:\n",
    "    base['priority_score'] = 1\n",
    "\n",
    "# Traffic intensity score (normalized traffic_delay_min)\n",
    "if 'traffic_delay_min' in base.columns:\n",
    "    td = base['traffic_delay_min'].fillna(0)\n",
    "    base['traffic_intensity_score'] = (td - td.min()) / (td.max() - td.min() + 1e-9)\n",
    "else:\n",
    "    base['traffic_intensity_score'] = 0\n",
    "\n",
    "# Carrier reliability: historical on-time rate\n",
    "if 'carrier' in base.columns:\n",
    "    carrier_on_time = base.groupby('carrier')['is_delayed'].apply(lambda s: 1 - s.mean())\n",
    "    base['carrier_reliability_score'] = base['carrier'].map(carrier_on_time).fillna(carrier_on_time.mean() if len(carrier_on_time)>0 else 0.5)\n",
    "else:\n",
    "    base['carrier_reliability_score'] = 0.5\n",
    "\n",
    "# Route risk: combine weather + traffic\n",
    "if 'weather_impact' in base.columns:\n",
    "    weather_map = {'Low':0.0, 'Moderate':0.5, 'High':1.0}\n",
    "    w = base['weather_impact'].map(weather_map).fillna(0.0)\n",
    "else:\n",
    "    w = 0.0\n",
    "base['route_risk_score'] = base['traffic_intensity_score'] * 0.6 + (w if isinstance(w, pd.Series) else 0) * 0.4\n",
    "\n",
    "# Warehouse utilization\n",
    "if 'stock_level' in base.columns and 'reorder_level' in base.columns:\n",
    "    base['warehouse_utilization'] = (base['stock_level'] / base['reorder_level']).replace([np.inf, -np.inf], np.nan).fillna(1.0)\n",
    "else:\n",
    "    base['warehouse_utilization'] = 1.0\n",
    "\n",
    "# Expected travel time: distance / average speed by vehicle type (fallback speed)\n",
    "speed_map = {'Truck':45.0, 'Van':55.0}\n",
    "if 'distance_km' in base.columns:\n",
    "    avg_speed = base['vehicle_type'].map(speed_map) if 'vehicle_type' in base.columns else 50.0\n",
    "    if isinstance(avg_speed, pd.Series):\n",
    "        avg_speed = avg_speed.fillna(50.0)\n",
    "    base['expected_travel_time_min'] = (base['distance_km'] / (avg_speed + 1e-9)) * 60\n",
    "else:\n",
    "    base['expected_travel_time_min'] = 0\n",
    "\n",
    "# Select features\n",
    "numeric_features = [\n",
    "    'distance_km','order_value','traffic_delay_min','promised_margin_min',\n",
    "    'priority_score','carrier_reliability_score','route_risk_score',\n",
    "    'warehouse_utilization','expected_travel_time_min','fuel_consumption_liters','tolls'\n",
    "]\n",
    "categorical_features = ['carrier','priority','weather_impact','product_category','destination_city']\n",
    "\n",
    "# Ensure columns exist\n",
    "for col in list(numeric_features):\n",
    "    if col not in base.columns:\n",
    "        base[col] = 0\n",
    "for col in list(categorical_features):\n",
    "    if col not in base.columns:\n",
    "        base[col] = 'Unknown'\n",
    "\n",
    "# Train/Test split (time-based if dates exist)\n",
    "base = base.sort_values('order_date')\n",
    "X = base[numeric_features + categorical_features]\n",
    "y = base['is_delayed']\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "clf = Pipeline(steps=[\n",
    "    ('preprocess', preprocess),\n",
    "    ('model', RandomForestClassifier(n_estimators=300, random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "clf.fit(X_train, y_train)\n",
    "probs = clf.predict_proba(X_test)[:,1]\n",
    "preds = (probs > 0.5).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': float(accuracy_score(y_test, preds)),\n",
    "    'precision': float(precision_score(y_test, preds, zero_division=0)),\n",
    "    'recall': float(recall_score(y_test, preds, zero_division=0)),\n",
    "    'f1': float(f1_score(y_test, preds, zero_division=0)),\n",
    "    'roc_auc': float(roc_auc_score(y_test, probs)) if len(np.unique(y_test))>1 else None\n",
    "}\n",
    "print('Metrics:', metrics)\n",
    "\n",
    "# Corrective actions\n",
    "cost_of_delay = 200.0\n",
    "cost_of_action = 50.0\n",
    "risk = pd.Series(probs, index=X_test.index)\n",
    "base.loc[X_test.index, 'delay_probability'] = risk\n",
    "\n",
    "def recommend(p):\n",
    "    if p > 0.8:\n",
    "        action = 'Reroute or Reassign or Expedite'\n",
    "    elif p > 0.5:\n",
    "        action = 'Monitor closely'\n",
    "    else:\n",
    "        action = 'No action required'\n",
    "    expected_saving = p * cost_of_delay - (cost_of_action if action != 'No action required' else 0)\n",
    "    return action, expected_saving\n",
    "\n",
    "rec = risk.apply(lambda p: recommend(p))\n",
    "base.loc[X_test.index, 'recommended_action'] = rec.apply(lambda x: x[0])\n",
    "base.loc[X_test.index, 'expected_saving'] = rec.apply(lambda x: x[1])\n",
    "\n",
    "# Save artifacts\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "joblib.dump(clf, os.path.join('models','model.pkl'))\n",
    "base.to_csv(os.path.join('data','final_dataset.csv'), index=False)\n",
    "print('Saved model to models/model.pkl and dataset to data/final_dataset.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
